smarts:
  # Environment
  sumo_gui: False # If True, enables sumo-gui display.
  head: False
  img_meters: 50 # Observation image area size in meters.
  img_pixels: 112 # Observation image size in pixels.
  num_stack: 3 # Number of frames to stack as input to policy network.
  sumo_scenarios: 
# SUMO Training 

    - "3lane_cruise_single_agent"
    - "3lane_merge_single_agent"
    - "3lane_overtake"
    - "1_to_1lane_left_turn_c"

    - "1_to_2lane_left_turn_c"
    - "1_to_2lane_left_turn_t"

  smarts_scenarios:
# SMARTS ZOO Training

    - "3lane_cruise_single_agent_social"
    - "1_to_2lane_left_turn_t_social"
  
  itra_scenarios:
# ITRA Training 

    - "3lane_cruise_single_agent_itra_batch"
    - "3lane_single_agent_itra"
    - "1_to_1lane_left_turn_c_itra"
    - "1_to_1lane_left_turn_c_itra_stop"
    - "1_to_2lane_left_turn_c_itra"
    - "1_to_2lane_left_turn_t_itra"

  itra_evaluation_scenarios:
  # ITRA Evaluation
    - "eval_3lane_cruise_single_agent_itra_batch"
    - "eval_3lane_single_agent_itra"
    - "eval_1_to_1lane_left_turn_c_itra"
    - "eval_1_to_1lane_left_turn_c_itra_stop"
    - "eval_1_to_2lane_left_turn_c_itra"
    - "eval_1_to_2lane_left_turn_t_itra"

  # Training
  # epochs: 5_000 # Number of training loops.

  # # Training per scenario
  # train_steps: 100_000
  # checkpoint_freq: 50_000 # Save a model every checkpoint_freq calls to env.step().
  # eval_eps: 100 # Number of evaluation epsiodes.
  # eval_freq: 50_000 # Evaluate the trained model every eval_freq steps and save the best model.

  # # Policy
  # alg: PPO  # Stable Baselines3 algorithm.
