# Explanation

## Overall Algorithm

My approach of this problem is consistent of 2 parts. 

The first part is proposing a future way points series given the current observation. This part is mainly relying on the waypoints and mission goal position provided in the observation space. A bezier curve is used to fit the waypoints and generate a smooth path. Then after a speed is chosen, the next goal position for the ego car will be generated by the bezier curve. 

The second part is a neural network in charge of the safety score of the proposed speed. A trained neural network is used for classfying the action into 6 categories of collision, wrong way, on shoulder, off road, off route. The data is collected offlined. The input includes a bird view 256 x 256 image, ego position, ego heading, action, the future 5 waypoints. It is a neural network combined with a CNN and MLP for the mixed input data. 

Below is the general idea of my current algorithm implemented within the time constraint.  

1. Generate a smoothed bezier curve based on the waypoints provided in the observation space for the ego car. 

2. Score the current collision probability by feeding in the mnn model with the current bird view image, ego car position, heading, and the future 5 waypoints. 

3. Get a list of the surrounding dangerous neighbors of the ego car. Identity whether the danger is mainly from the front or back. (This is a hack as I later realize that I didn't label the collision as front collision or back collision, and cannot tell it from the model directly. And I'm running out of time to regenerate data and retrain the model.)

4. If the danger is from front, based on the collision probability predicted by the mnn model I trained, a speed is computed by a sigmoid function with highest value of 1 and lowest 0. When 1 means full speed, and 0 means stop. 

5. Otherwise, keep the speed. 

## MNN Model Data Generation

The code I used to generate the labeled data for the safety model is in the `competition/track1/generator/` folder. It will stores a image file for the bird view image provided in the observation space, and the ego position, heading, action and future 5 waypoints. The label is whehter this action will lead to collision, off shoulder, off route, off road, wrong way, and safe within the next 8 steps. 

## CNN + MLP Model 

For the network architecture, see the code in `competition/track1/classifier/mnn.py`.
For the training code, see `competition/track1/classifier/train.py`.

More detailed documentation overleaf file: https://www.overleaf.com/read/gtbjhybmkxpk
GitHub link: https://github.com/yuant95/SMARTS_VCR